# TOY_LLAMA3_RAG_CHAT_MOCKINGBIRD
> [토이프로젝트] LLAMA3:8B Quantization 모델 활용 카카오톡/DM 앵무새봇

#### 목적
- 1차: 내 말투와 대화 방식을 흉내내는 봇을 만들자
- 2차: 나 대신 간단한 일상 채팅 답장을 처리해주는 간단한 에이전트를 만들자

#### 투입데이터

- 대화 상황에서 내가 보낸 카카오톡 전문
- 상대방 대화 기록 활용 동의 취득 필요

#### 사용기술
1. 모델: 속도와 비용 때문에 LLAMA3:8B 채택. Ollama 를 통해 이미 Quantization 되어 배포된 모델을 사용. 추후 한국어 튜닝된 모델 추가 성능 평가 후 업데이트 예정.
3. 언어: Python
4. RAG(Retrieval-Augmented Generation): 
   기존에 존재했던 채팅(메시지)를 참조하되, 메세지의 전문이 아닌 질문 내용과 가장 관련있는(유사한) 내용만 추려 프롬프트에 던지기 위해 채택.
   카카오톡 내보내기로 받은 txt 파일을 Document 형식으로 전처리 하여 사용
   
   (연구과제1) 메타데이터 검색 기반 여러 필터링 기능 구현 필요
   
   (연구과제2) 개별 메세지가 아니라, 맥락을 가진 대화를 기준으로 챗을 묶어 요약한 문서를 참조해 비슷한 맥락의 질문인 경우 유사한 반응을 돌려주도록 세팅
   (2-1) 무엇을 기준으로 챗을 묶을 것인지? 시계열 패턴, 대화 주제(핵심 키워드, 핵심 요약... 언어학 관련 논문 참조하여 대화를 정의할 수 있는 방안 찾아볼 것)
   
6. Vector DB
   (연구과제1) 챗 전체를 미리 다 벡터화 하고 시작하는게 아니라 내용 요약만 벡터 라이징하고 필요한 경우 부분적으로 벡터에 추가하는 식으로 작동하게 바꾸어 속도 높이기
   
8. 프롬프트 튜닝
   - 대화 템플릿 구성 완료
   - (연구과제1) Chain-of-thought 기법으로 성능 올리기
   

   

   
   

